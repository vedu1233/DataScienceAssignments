{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eedfa5-75bb-4267-87fb-129845d88379",
   "metadata": {},
   "source": [
    "# Classification Using Artificial Neural Networks with Hyperparameter Tuning on Alphabets Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1b26f-dafb-42fa-a510-bb71fc701f8d",
   "metadata": {},
   "source": [
    "#Overview\n",
    "\n",
    "In this assignment, you will be tasked with developing a classification model using Artificial Neural Networks (ANNs) to classify data points from the \"Alphabets_data.csv\" dataset into predefined categories of alphabets. This exercise aims to deepen your understanding of ANNs and the significant role hyperparameter tuning plays in enhancing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fffe81a-ad91-4292-beaf-2ec0cc384f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03bacb1b-3186-4fe9-b0c5-16aa0383cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ddc6f3c-ecf3-4492-b19f-dd3db8e19e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Alphabets_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee78695-9068-4700-955d-42adb8d7388f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59604ac2-8108-49e7-b44d-235888440692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61e73d1-b57c-4b75-8d71-549a085db2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    object\n",
       "xbox       int64\n",
       "ybox       int64\n",
       "width      int64\n",
       "height     int64\n",
       "onpix      int64\n",
       "xbar       int64\n",
       "ybar       int64\n",
       "x2bar      int64\n",
       "y2bar      int64\n",
       "xybar      int64\n",
       "x2ybar     int64\n",
       "xy2bar     int64\n",
       "xedge      int64\n",
       "xedgey     int64\n",
       "yedge      int64\n",
       "yedgex     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d184d84-b7b5-48f1-b7ba-e2022bccb948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee10fa0e-7a9d-4a88-9f4d-97b45b72e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8205d6c-6b06-47c0-93a7-dc50c2592114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "777bc727-08b9-49d7-adcd-ad67fb24bf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 18668\n",
      "Number of features: 16\n",
      "Number of classes: 26\n"
     ]
    }
   ],
   "source": [
    "# Summarize key features\n",
    "print(\"Number of samples:\", len(df))\n",
    "print(\"Number of features:\", len(df.columns) - 1)  # Excluding the target column\n",
    "print(\"Number of classes:\", len(df['letter'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da0b281a-027f-49d5-a171-b6cbd9b66d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target variable\n",
    "X = df.iloc[:,1:16]\n",
    "y = df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1f3910-1209-4e66-8991-d3440184d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "### label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd8fcd16-7dde-4b63-bb45-cb09cdcd1b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14934, 15), (3734, 15), (14934,), (3734,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Split into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=41)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "024aacd7-33f2-4b6d-9b5d-0a392eac24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aedaa9df-fa18-475a-b044-8211df288cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">234</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │             \u001b[38;5;34m234\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">626</span> (2.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m626\u001b[0m (2.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">626</span> (2.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m626\u001b[0m (2.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Initialize the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(units=16, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "# Add the second hidden layer (optional)\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "# Compile the ANN\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "044201b4-eb6c-4d9c-bd9b-9791088ad820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1533 - loss: 2.8857 - val_accuracy: 0.5147 - val_loss: 1.6348\n",
      "Epoch 2/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5218 - loss: 1.5773 - val_accuracy: 0.6191 - val_loss: 1.3066\n",
      "Epoch 3/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 1.3182 - val_accuracy: 0.6566 - val_loss: 1.1775\n",
      "Epoch 4/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6401 - loss: 1.2070 - val_accuracy: 0.6647 - val_loss: 1.1110\n",
      "Epoch 5/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6591 - loss: 1.1350 - val_accuracy: 0.6774 - val_loss: 1.0434\n",
      "Epoch 6/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6843 - loss: 1.0469 - val_accuracy: 0.6908 - val_loss: 1.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6995 - loss: 1.0106 - val_accuracy: 0.7102 - val_loss: 0.9677\n",
      "Epoch 8/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.9857 - val_accuracy: 0.7135 - val_loss: 0.9457\n",
      "Epoch 9/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.9471 - val_accuracy: 0.7149 - val_loss: 0.9220\n",
      "Epoch 10/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.9135 - val_accuracy: 0.7202 - val_loss: 0.8967\n",
      "Epoch 11/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.9129 - val_accuracy: 0.7363 - val_loss: 0.8700\n",
      "Epoch 12/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.8785 - val_accuracy: 0.7289 - val_loss: 0.8578\n",
      "Epoch 13/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.8610 - val_accuracy: 0.7383 - val_loss: 0.8400\n",
      "Epoch 14/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 0.8357 - val_accuracy: 0.7463 - val_loss: 0.8277\n",
      "Epoch 15/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.8328 - val_accuracy: 0.7376 - val_loss: 0.8263\n",
      "Epoch 16/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.8401 - val_accuracy: 0.7470 - val_loss: 0.8153\n",
      "Epoch 17/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.8267 - val_accuracy: 0.7477 - val_loss: 0.8055\n",
      "Epoch 18/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7469 - loss: 0.8134 - val_accuracy: 0.7590 - val_loss: 0.7849\n",
      "Epoch 19/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.7892 - val_accuracy: 0.7450 - val_loss: 0.7961\n",
      "Epoch 20/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.7854 - val_accuracy: 0.7624 - val_loss: 0.7666\n",
      "Epoch 21/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7560 - loss: 0.7844 - val_accuracy: 0.7584 - val_loss: 0.7688\n",
      "Epoch 22/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.7694 - val_accuracy: 0.7657 - val_loss: 0.7599\n",
      "Epoch 23/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.7651 - val_accuracy: 0.7651 - val_loss: 0.7568\n",
      "Epoch 24/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.7619 - val_accuracy: 0.7711 - val_loss: 0.7501\n",
      "Epoch 25/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7633 - loss: 0.7704 - val_accuracy: 0.7684 - val_loss: 0.7378\n",
      "Epoch 26/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.7378 - val_accuracy: 0.7664 - val_loss: 0.7364\n",
      "Epoch 27/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.7636 - val_accuracy: 0.7784 - val_loss: 0.7314\n",
      "Epoch 28/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.7200 - val_accuracy: 0.7771 - val_loss: 0.7237\n",
      "Epoch 29/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.7257 - val_accuracy: 0.7738 - val_loss: 0.7231\n",
      "Epoch 30/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7713 - loss: 0.7297 - val_accuracy: 0.7845 - val_loss: 0.7119\n",
      "Epoch 31/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.7167 - val_accuracy: 0.7851 - val_loss: 0.7097\n",
      "Epoch 32/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.7168 - val_accuracy: 0.7805 - val_loss: 0.7114\n",
      "Epoch 33/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.7136 - val_accuracy: 0.7845 - val_loss: 0.7056\n",
      "Epoch 34/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.7172 - val_accuracy: 0.7798 - val_loss: 0.6998\n",
      "Epoch 35/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.7099 - val_accuracy: 0.7831 - val_loss: 0.6902\n",
      "Epoch 36/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.6778 - val_accuracy: 0.7831 - val_loss: 0.6977\n",
      "Epoch 37/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7811 - loss: 0.6948 - val_accuracy: 0.7858 - val_loss: 0.6834\n",
      "Epoch 38/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.6980 - val_accuracy: 0.7791 - val_loss: 0.6934\n",
      "Epoch 39/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.6945 - val_accuracy: 0.7885 - val_loss: 0.6812\n",
      "Epoch 40/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.7031 - val_accuracy: 0.7791 - val_loss: 0.6803\n",
      "Epoch 41/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.6877 - val_accuracy: 0.7858 - val_loss: 0.6752\n",
      "Epoch 42/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.6729 - val_accuracy: 0.7878 - val_loss: 0.6743\n",
      "Epoch 43/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.6810 - val_accuracy: 0.7972 - val_loss: 0.6668\n",
      "Epoch 44/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.6753 - val_accuracy: 0.7952 - val_loss: 0.6700\n",
      "Epoch 45/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.6806 - val_accuracy: 0.7865 - val_loss: 0.6749\n",
      "Epoch 46/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.6749 - val_accuracy: 0.7918 - val_loss: 0.6672\n",
      "Epoch 47/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.6751 - val_accuracy: 0.7892 - val_loss: 0.6657\n",
      "Epoch 48/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7927 - loss: 0.6567 - val_accuracy: 0.7965 - val_loss: 0.6650\n",
      "Epoch 49/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.6534 - val_accuracy: 0.7992 - val_loss: 0.6537\n",
      "Epoch 50/50\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7855 - loss: 0.6635 - val_accuracy: 0.7979 - val_loss: 0.6498\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db41dce-9807-40d9-b239-1ac3df230330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.6546\n",
      "train Accuracy: 79.62%\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[[527   3   0   0   0   3  10   2   0   2  13   2   0   0   6   2   6   5\n",
      "   10   0   3   2   0   7   8   0]\n",
      " [  0 448   0  29   5   2   3   1   0   2   8   0   0   0   3  11   0  33\n",
      "   18   0   0   1   1   1   2   0]\n",
      " [  0   0 478   0  12   0  15   3   0   0  18   5   0   0  14   0   2   0\n",
      "    1   6  17   2   0   0   0   0]\n",
      " [  0  52   0 464   8   1   1  25   0   5   1   4   4   5   7   4   0  29\n",
      "    0   1   6   0   0   0   0   0]\n",
      " [  0   6  17   7 396   0  46   2   0   0   8   5   0   0   0   0  14   2\n",
      "   11   7   0   0   0  36   0  28]\n",
      " [  3  43   1   6   2 436   1   9  16   1   1   0   0   0   2  28   0   0\n",
      "    8  15   0   6   0   5  13   0]\n",
      " [  2  30  19   0  13  11 417   5   0   0   3   1   1   0   9  11  31  12\n",
      "    2   0  13   4   3   0   0   0]\n",
      " [ 10   9   0  32   1   5   7 368   0   0  21   3   3  17  10   6   5  40\n",
      "    2   1  11   4   0   2   2   0]\n",
      " [  0   3   0   4   3   6   2   1 333  19   1   2   0   0   0   4   2   0\n",
      "   35   2   0   0   0  16   5   0]\n",
      " [  1   3   0   2   1   3   2   6  41 445   2   1   2   0   4   1   4   5\n",
      "   16   0   0   0   0  16   0   6]\n",
      " [  5   2   7   1   8   0   6  18   0   5 442   5   1   3   6   2   0  35\n",
      "    0   0   2   0   0  28   0   0]\n",
      " [  1   1   1   1   9   1   3   7   0   0  19 455   1   0   6   0   4   0\n",
      "   15   0   1   0   0  25   1   3]\n",
      " [  1   8   0   0   0   0   0   0   0   0   0   1 539   2   8   0   0   3\n",
      "    0   0   1   0  17   0   0   0]\n",
      " [  0   6   6   3   2   0   1  26   0   0   4   0   8 463   4   0   0  14\n",
      "    0   0  10   2  13   0   0   0]\n",
      " [  7   6   9   5   0   0  14   6   0   0   0   1   4   5 462   7   4  26\n",
      "    0   1   4   0  25   0   0   0]\n",
      " [  0  11   0   0   0  20   6   1   0   0   0   0   0   0   7 550   6   2\n",
      "    1   1   0   5   2   0  18   0]\n",
      " [ 27   3   0   3   3   0  18   0   0   0   0   4   0   0  21   6 490   2\n",
      "    9   0   1   2   2   1   6   4]\n",
      " [  6  38   4  20   4   2   7  14   0   5  15   0   4   0  16   0   1 438\n",
      "    0   0   0   0   2   2   0   0]\n",
      " [  4  55   0  14  35  12   9   1  10  14   0   8   0   0   0   6   9   3\n",
      "  351   0   0   0   0   4   3  26]\n",
      " [  0   0   7   1  19  19   2   1   8   0   2   0   0   0  14   1   1   8\n",
      "    2 505   2   9   0   6  14   5]\n",
      " [  0   0   3   1   0   0   5   9   0   0   3   1  10   8  34   1   5   3\n",
      "    0   0 511   3  10   1   0   0]\n",
      " [  2  14   0   0   2   0   1   0   0   0   0   0   0   1   5   2   1   2\n",
      "    0   3   0 495  18   0  18   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  19   1   1   1   2   0\n",
      "    0   0   2   1 551   0   0   0]\n",
      " [  3   1   0   8   4   1   6   4   1   4  15   7   0   0   0   1   6   0\n",
      "    3   1   4   0   0 445   4   3]\n",
      " [  1   0   0   1   0   4   2   0   1   0   0   0   2   0   0  33  18   0\n",
      "    7   2   1  31   2   5 494   0]\n",
      " [  2   2   0   0  29   0   1   0   8  10   2   5   0   0   0   0  10   3\n",
      "   39   1   0   0   0   7   0 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       611\n",
      "           1       0.60      0.79      0.68       568\n",
      "           2       0.87      0.83      0.85       573\n",
      "           3       0.77      0.75      0.76       617\n",
      "           4       0.71      0.68      0.69       585\n",
      "           5       0.83      0.73      0.78       596\n",
      "           6       0.71      0.71      0.71       587\n",
      "           7       0.72      0.66      0.69       559\n",
      "           8       0.80      0.76      0.78       438\n",
      "           9       0.87      0.79      0.83       561\n",
      "          10       0.76      0.77      0.77       576\n",
      "          11       0.89      0.82      0.86       554\n",
      "          12       0.90      0.93      0.92       580\n",
      "          13       0.92      0.82      0.87       562\n",
      "          14       0.72      0.79      0.75       586\n",
      "          15       0.81      0.87      0.84       630\n",
      "          16       0.79      0.81      0.80       602\n",
      "          17       0.66      0.76      0.70       578\n",
      "          18       0.66      0.62      0.64       564\n",
      "          19       0.92      0.81      0.86       626\n",
      "          20       0.87      0.84      0.85       608\n",
      "          21       0.87      0.88      0.88       564\n",
      "          22       0.85      0.95      0.90       578\n",
      "          23       0.73      0.85      0.79       521\n",
      "          24       0.84      0.82      0.83       604\n",
      "          25       0.84      0.76      0.80       506\n",
      "\n",
      "    accuracy                           0.80     14934\n",
      "   macro avg       0.80      0.80      0.80     14934\n",
      "weighted avg       0.80      0.80      0.80     14934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### evaluate the model\n",
    "# Evaluate the model on the train set\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(f'train Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Make predictions on the train set\n",
    "yhat_train = model.predict(X_train)\n",
    "y_pred_classes = yhat_train.argmax(axis=-1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_train, y_pred_classes ))\n",
    "print(classification_report(y_train, y_pred_classes ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6c0e6e9-9625-420e-958b-694fb85e2e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[[124   1   0   0   1   1   2   1   0   1   2   0   1   0   3   0   1   3\n",
      "    0   0   1   0   0   3   0   0]\n",
      " [  1 133   0   9   3   0   0   0   0   1   1   0   0   0   0   1   0   9\n",
      "    1   0   0   0   0   1   0   2]\n",
      " [  0   0 110   0   4   0   4   0   0   0   5   0   0   0   4   0   0   0\n",
      "    0   2   8   0   0   0   0   0]\n",
      " [  1   9   0 114   1   1   1   4   0   1   1   0   0   1   2   1   0   5\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   1   6   0  96   1  10   2   0   0   5   0   0   0   0   0   1   0\n",
      "    2   0   0   0   0   9   0   7]\n",
      " [  0  12   0   1   0 115   0   5   2   3   0   0   0   0   0   6   0   0\n",
      "    3   3   0   1   0   2   3   0]\n",
      " [  1   6   6   1   2   1 108   1   0   0   2   1   0   0   4   2  10   1\n",
      "    3   0   4   2   1   0   0   0]\n",
      " [  5   2   0   3   0   1   2  88   0   0   9   0   1   7   5   3   2  10\n",
      "    0   0   0   5   0   1   1   0]\n",
      " [  0   1   0   1   0   2   0   0  62   1   1   2   0   0   0   2   0   0\n",
      "    8   0   0   0   0   1   5   0]\n",
      " [  1   2   0   0   0   2   1   0  16 107   0   0   1   0   6   0   2   2\n",
      "   12   0   0   0   0   2   0   0]\n",
      " [  2   0   0   0   0   0   0   4   0   0 108   4   1   2   2   0   0  14\n",
      "    2   0   0   0   0   3   0   0]\n",
      " [  1   0   0   0   2   0   3   0   1   0   5  98   0   0   2   0   0   0\n",
      "    1   0   0   0   0   5   0   1]\n",
      " [  1   2   0   0   0   0   0   0   0   0   0   0 143   1   2   0   0   1\n",
      "    0   0   0   0   2   0   0   0]\n",
      " [  0   3   1   2   0   0   0   5   0   0   0   0   7  98   0   1   0   4\n",
      "    0   0   3   0   2   0   0   0]\n",
      " [  0   2   2   1   0   0   4   1   0   0   0   0   4   2  99   3   2   8\n",
      "    0   0   0   0   4   0   0   0]\n",
      " [  0   2   0   0   0   8   4   0   0   0   0   0   0   0   2 126   1   2\n",
      "    0   0   1   1   1   0   4   0]\n",
      " [  6   1   0   0   2   0   8   0   0   0   0   3   0   0   6   1 121   0\n",
      "    2   0   1   1   1   0   1   4]\n",
      " [  0  16   0   5   1   0   0   4   0   1   5   0   0   0   1   0   0 124\n",
      "    0   0   0   0   0   2   0   0]\n",
      " [  2  14   0   3  15   2   6   0   6   3   0   1   0   0   0   1   2   0\n",
      "   98   1   0   0   0   1   0  10]\n",
      " [  0   0   0   2   1   3   2   0   1   0   0   0   0   0   1   0   0   0\n",
      "    2 106   0   1   0   0   3   0]\n",
      " [  0   0   3   0   0   0   0   3   0   0   2   0   5   2   5   0   1   1\n",
      "    0   0 132   0   5   1   0   0]\n",
      " [  1   6   0   0   0   0   0   1   0   0   0   0   0   1   2   3   0   1\n",
      "    0   0   0 120   4   0   3   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   1\n",
      "    0   0   0   1 140   0   0   0]\n",
      " [  0   0   0   3   2   1   4   1   0   0   9   2   0   0   1   0   2   0\n",
      "    0   1   0   0   0 130   0   1]\n",
      " [  2   0   0   0   0   1   0   0   0   0   0   0   0   0   0   8   7   0\n",
      "    1   2   1   7   1   5 107   0]\n",
      " [  0   0   0   0  11   0   0   0   4   4   0   0   0   0   0   0   0   2\n",
      "   10   0   0   0   0   0   0 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       145\n",
      "           1       0.62      0.82      0.71       162\n",
      "           2       0.86      0.80      0.83       137\n",
      "           3       0.79      0.80      0.79       143\n",
      "           4       0.68      0.69      0.68       140\n",
      "           5       0.83      0.74      0.78       156\n",
      "           6       0.68      0.69      0.69       156\n",
      "           7       0.73      0.61      0.66       145\n",
      "           8       0.67      0.72      0.70        86\n",
      "           9       0.88      0.69      0.78       154\n",
      "          10       0.70      0.76      0.73       142\n",
      "          11       0.88      0.82      0.85       119\n",
      "          12       0.85      0.94      0.89       152\n",
      "          13       0.86      0.78      0.82       126\n",
      "          14       0.67      0.75      0.71       132\n",
      "          15       0.80      0.83      0.81       152\n",
      "          16       0.80      0.77      0.78       158\n",
      "          17       0.66      0.78      0.71       159\n",
      "          18       0.68      0.59      0.63       165\n",
      "          19       0.92      0.87      0.89       122\n",
      "          20       0.87      0.82      0.85       160\n",
      "          21       0.86      0.85      0.85       142\n",
      "          22       0.86      0.95      0.90       148\n",
      "          23       0.78      0.83      0.80       157\n",
      "          24       0.84      0.75      0.80       142\n",
      "          25       0.80      0.77      0.79       134\n",
      "\n",
      "    accuracy                           0.78      3734\n",
      "   macro avg       0.79      0.78      0.78      3734\n",
      "weighted avg       0.78      0.78      0.78      3734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "yhat_test = model.predict(X_test)\n",
    "y_pred_classes1 = yhat_test.argmax(axis=-1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred_classes1 ))\n",
    "print(classification_report(y_test, y_pred_classes1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9e93a-09cd-4b31-b78c-c836c37e8a43",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11ed9868-00b8-41f8-a7b2-70d271f58543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def create_model(hidden_layers=1, units=16, activation='relu', learning_rate=0.001):  # Model Creation Function\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, activation=activation, input_dim=X_train.shape[1]))\n",
    "\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(units=units, activation=activation))\n",
    "\n",
    "    model.add(Dense(units=len(np.unique(y)), activation='softmax'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3d10d7c-e7a4-4f71-b1ab-1f8dd9941dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(hidden_layers, units, activation, learning_rate):        #Model Evaluation Function\n",
    "    model = create_model(hidden_layers=hidden_layers, units=units, activation=activation, learning_rate=learning_rate)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2abd860b-69fa-4756-811d-c06e1c6508b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'activation': 'relu', 'hidden_layers': 1, 'learning_rate': 0.001, 'units': 8} - Score: 0.6912158727645874\n",
      "Params: {'activation': 'relu', 'hidden_layers': 1, 'learning_rate': 0.001, 'units': 16} - Score: 0.7793251276016235\n",
      "Params: {'activation': 'relu', 'hidden_layers': 1, 'learning_rate': 0.001, 'units': 32} - Score: 0.8286020159721375\n",
      "Params: {'activation': 'relu', 'hidden_layers': 1, 'learning_rate': 0.01, 'units': 8} - Score: 0.7062131762504578\n",
      "Params: {'activation': 'relu', 'hidden_layers': 1, 'learning_rate': 0.01, 'units': 16} - Score: 0.7935190200805664\n",
      "Params: {'activation': 'relu', 'hidden_layers': 1, 'learning_rate': 0.01, 'units': 32} - Score: 0.8476164937019348\n",
      "Params: {'activation': 'relu', 'hidden_layers': 2, 'learning_rate': 0.001, 'units': 8} - Score: 0.6815747022628784\n",
      "Params: {'activation': 'relu', 'hidden_layers': 2, 'learning_rate': 0.001, 'units': 16} - Score: 0.8012855052947998\n",
      "Params: {'activation': 'relu', 'hidden_layers': 2, 'learning_rate': 0.001, 'units': 32} - Score: 0.8580610752105713\n",
      "Params: {'activation': 'relu', 'hidden_layers': 2, 'learning_rate': 0.01, 'units': 8} - Score: 0.675147294998169\n",
      "Params: {'activation': 'relu', 'hidden_layers': 2, 'learning_rate': 0.01, 'units': 16} - Score: 0.778521716594696\n",
      "Params: {'activation': 'relu', 'hidden_layers': 2, 'learning_rate': 0.01, 'units': 32} - Score: 0.8618103861808777\n",
      "Params: {'activation': 'relu', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 8} - Score: 0.6628280878067017\n",
      "Params: {'activation': 'relu', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 16} - Score: 0.780128538608551\n",
      "Params: {'activation': 'relu', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 32} - Score: 0.8666309714317322\n",
      "Params: {'activation': 'relu', 'hidden_layers': 3, 'learning_rate': 0.01, 'units': 8} - Score: 0.6154258251190186\n",
      "Params: {'activation': 'relu', 'hidden_layers': 3, 'learning_rate': 0.01, 'units': 16} - Score: 0.7696839570999146\n",
      "Params: {'activation': 'relu', 'hidden_layers': 3, 'learning_rate': 0.01, 'units': 32} - Score: 0.7795929312705994\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 1, 'learning_rate': 0.001, 'units': 8} - Score: 0.6456882953643799\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 1, 'learning_rate': 0.001, 'units': 16} - Score: 0.753347635269165\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 1, 'learning_rate': 0.001, 'units': 32} - Score: 0.8162828087806702\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 1, 'learning_rate': 0.01, 'units': 8} - Score: 0.6847884058952332\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 1, 'learning_rate': 0.01, 'units': 16} - Score: 0.7787895202636719\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 1, 'learning_rate': 0.01, 'units': 32} - Score: 0.8465452790260315\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 2, 'learning_rate': 0.001, 'units': 8} - Score: 0.6561328172683716\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 2, 'learning_rate': 0.001, 'units': 16} - Score: 0.7712908387184143\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 2, 'learning_rate': 0.001, 'units': 32} - Score: 0.858596682548523\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 2, 'learning_rate': 0.01, 'units': 8} - Score: 0.6850562691688538\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 2, 'learning_rate': 0.01, 'units': 16} - Score: 0.7766470313072205\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 2, 'learning_rate': 0.01, 'units': 32} - Score: 0.8366363048553467\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 8} - Score: 0.6464917063713074\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 16} - Score: 0.7889662384986877\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 32} - Score: 0.8805570602416992\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.01, 'units': 8} - Score: 0.647027313709259\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.01, 'units': 16} - Score: 0.7723620533943176\n",
      "Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.01, 'units': 32} - Score: 0.7961971163749695\n",
      "Best Score: 0.8805570602416992\n",
      "Best Params: {'activation': 'tanh', 'hidden_layers': 3, 'learning_rate': 0.001, 'units': 32}\n"
     ]
    }
   ],
   "source": [
    "#Perform Hyperparameter Tuning\n",
    "param_grid = {                                        \n",
    "    'hidden_layers': [1, 2, 3],\n",
    "    'units': [8, 16, 32],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'learning_rate': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    score = evaluate_model(**params)\n",
    "    print(f\"Params: {params} - Score: {score}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f84a0924-6b17-4444-b514-12243696bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.4160 - loss: 2.1684\n",
      "Epoch 2/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 1.0097\n",
      "Epoch 3/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.7738\n",
      "Epoch 4/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.6480\n",
      "Epoch 5/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.5667\n",
      "Epoch 6/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.5020\n",
      "Epoch 7/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.4388\n",
      "Epoch 8/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.4152\n",
      "Epoch 9/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.3866\n",
      "Epoch 10/10\n",
      "\u001b[1m1494/1494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.3618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f8edd62c30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters from the tuning process\n",
    "best_hidden_layers = best_params['hidden_layers']\n",
    "best_units = best_params['units']\n",
    "best_activation = best_params['activation']\n",
    "best_learning_rate = best_params['learning_rate']    \n",
    "\n",
    "# Create the final model with the best parameters\n",
    "final_model = create_model(\n",
    "    hidden_layers=best_hidden_layers,\n",
    "    units=best_units,\n",
    "    activation=best_activation,\n",
    "    learning_rate=best_learning_rate\n",
    ")\n",
    "\n",
    "# Train the final model on the full training data\n",
    "final_model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b467cd75-fe79-419f-b66d-635b854fe0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.4236\n",
      "Test Loss: 0.4190920889377594\n",
      "Test Accuracy: 0.8727905750274658\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test data\n",
    "loss, accuracy = final_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c5de094-e5a1-4ea8-b8df-bca1557770e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "[[578   5   0   0   2   0   1   0   0   1   0   0   1   1   0   1   4   4\n",
      "    1   1   3   3   3   1   0   1]\n",
      " [  0 513   0  14   4   3   1   1   0   4   0   0   0   1   0   0   0  15\n",
      "    6   3   0   2   0   0   1   0]\n",
      " [  0   0 530   0  13   0  10   2   0   0   0   2   0   0   8   0   1   2\n",
      "    1   0   3   0   1   0   0   0]\n",
      " [  0  27   0 538   0   1   0  20   0   1   0   0   1   3   3   1   0  18\n",
      "    2   0   2   0   0   0   0   0]\n",
      " [  0   2   1   0 535   2  12   1   0   0   1   4   0   0   0   0   4   2\n",
      "    3   5   0   0   0   0   0  13]\n",
      " [  0   4   1   1   7 518   0   2   4   3   0   0   0   2   1  14   1   0\n",
      "   15   7   0   2   2   0  10   2]\n",
      " [  0   4  11   4   5   2 523   2   0   0   2   6   2   0   3   5   2   2\n",
      "    8   0   2   3   1   0   0   0]\n",
      " [  4   7   1  21   0   6   1 448   0   0  14   1   1   2   5   5   2  32\n",
      "    0   0   2   3   0   1   3   0]\n",
      " [  0   2   1   3   1   7   1   0 382  23   0   1   0   0   0   1   0   0\n",
      "    5   0   0   0   0   3   3   5]\n",
      " [  1   1   0   5   0   0   0   1  13 523   0   1   1   0   3   0   3   2\n",
      "    7   0   0   0   0   0   0   0]\n",
      " [  1   5   1   6   4   0   3   8   0   0 513   3   0   0   0   0   0  14\n",
      "    5   2   2   0   0   9   0   0]\n",
      " [  1   3   4   0   9   0   4   1   0   2   0 501   1   1   0   0   3   0\n",
      "   12   0   3   0   0   7   1   1]\n",
      " [  2   3   0   0   0   0   0   0   0   0   0   0 546   3   2   0   0   0\n",
      "    0   0   2   0  22   0   0   0]\n",
      " [  0  10   0   8   0   0   0  10   0   0   2   0  10 481  13   0   0  21\n",
      "    0   0   0   3   4   0   0   0]\n",
      " [  2   1   2  11   0   0   1   3   0   0   0   0   2   5 512   3  11  16\n",
      "    0   0   3   1  13   0   0   0]\n",
      " [  1   6   0   3   1  32   4   1   2   0   0   0   0   0   2 571   2   1\n",
      "    0   0   0   1   0   0   3   0]\n",
      " [  4   3   0   2   5   0   6   2   0   1   0   0   0   0  14   4 546   2\n",
      "    2   0   1   0   1   0   3   6]\n",
      " [  0  26   0  16   1   1   1   4   0   2  12   1   3   1   3   0   2 500\n",
      "    1   0   0   0   1   3   0   0]\n",
      " [  0   9   0   0   9  10   3   0   3   0   0   6   0   0   0   0   0   0\n",
      "  509   2   0   0   0   3   2   8]\n",
      " [  0   1   1   2   8  11   0   1   3   0   0   0   1   1   0   1   0   3\n",
      "    4 559   4   1   0   3  19   3]\n",
      " [  3   1   7   2   1   0   1   5   0   0   1   0   4   1   2   0   3   0\n",
      "    0   0 571   3   3   0   0   0]\n",
      " [  0   4   0   0   1   2   1   2   0   0   0   0   1   5   2   4   0   1\n",
      "    0   3   1 516  18   0   3   0]\n",
      " [  1   1   0   0   0   0   1   0   0   0   0   0   7   2   4   0   0   0\n",
      "    0   2   0   2 558   0   0   0]\n",
      " [  0   1   0   4  15   3   2   0   4   6  10   9   0   0   1   0   0   0\n",
      "    1   1   0   0   0 463   1   0]\n",
      " [  0   2   0   1   0   0   0   0   0   1   0   3   0   0   0   3  11   0\n",
      "    0   1   3   3   0   2 574   0]\n",
      " [  0   1   0   0  14   0   0   0   0   1   1   0   0   0   0   0   4   1\n",
      "   14   2   0   0   0   0   0 468]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       611\n",
      "           1       0.80      0.90      0.85       568\n",
      "           2       0.95      0.92      0.94       573\n",
      "           3       0.84      0.87      0.86       617\n",
      "           4       0.84      0.91      0.88       585\n",
      "           5       0.87      0.87      0.87       596\n",
      "           6       0.91      0.89      0.90       587\n",
      "           7       0.87      0.80      0.84       559\n",
      "           8       0.93      0.87      0.90       438\n",
      "           9       0.92      0.93      0.93       561\n",
      "          10       0.92      0.89      0.91       576\n",
      "          11       0.93      0.90      0.92       554\n",
      "          12       0.94      0.94      0.94       580\n",
      "          13       0.94      0.86      0.90       562\n",
      "          14       0.89      0.87      0.88       586\n",
      "          15       0.93      0.91      0.92       630\n",
      "          16       0.91      0.91      0.91       602\n",
      "          17       0.79      0.87      0.82       578\n",
      "          18       0.85      0.90      0.88       564\n",
      "          19       0.95      0.89      0.92       626\n",
      "          20       0.95      0.94      0.94       608\n",
      "          21       0.95      0.91      0.93       564\n",
      "          22       0.89      0.97      0.93       578\n",
      "          23       0.94      0.89      0.91       521\n",
      "          24       0.92      0.95      0.94       604\n",
      "          25       0.92      0.92      0.92       506\n",
      "\n",
      "    accuracy                           0.90     14934\n",
      "   macro avg       0.90      0.90      0.90     14934\n",
      "weighted avg       0.90      0.90      0.90     14934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the train set\n",
    "yhat_train = final_model.predict(X_train)\n",
    "y_pred_classes = yhat_train.argmax(axis=-1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_train, y_pred_classes ))\n",
    "print(classification_report(y_train, y_pred_classes ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e5c51ad-46c3-4bcf-a1ed-40f8ac61a856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "[[137   1   0   0   0   0   1   0   0   1   0   0   2   0   0   0   1   1\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0 136   0   5   1   1   1   0   0   3   0   1   0   0   0   0   0   6\n",
      "    7   0   0   0   0   1   0   0]\n",
      " [  0   0 123   0   1   0   4   0   0   0   1   0   0   0   3   0   0   0\n",
      "    0   0   5   0   0   0   0   0]\n",
      " [  0   4   0 131   0   0   0   4   0   1   0   0   0   0   0   0   0   2\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   0   1   0 129   1   2   0   0   0   0   1   0   0   0   0   1   0\n",
      "    1   1   0   0   0   0   0   3]\n",
      " [  0   1   0   0   2 131   0   0   1   2   0   0   0   1   0   9   0   0\n",
      "    5   2   0   0   0   0   2   0]\n",
      " [  0   0   7   3   4   0 127   0   0   0   2   2   0   0   0   2   1   1\n",
      "    1   0   2   3   1   0   0   0]\n",
      " [  2   5   1   2   0   2   1 105   0   0   9   1   1   2   0   1   1   6\n",
      "    0   1   2   3   0   0   0   0]\n",
      " [  0   0   0   1   1   2   0   0  69   4   0   2   0   0   0   2   0   0\n",
      "    5   0   0   0   0   0   0   0]\n",
      " [  1   0   0   2   0   0   0   1   4 134   0   1   0   0   3   0   0   1\n",
      "    5   0   0   0   0   0   0   2]\n",
      " [  1   1   0   1   0   0   1   1   0   0 125   0   1   1   0   0   0   8\n",
      "    2   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   1   0   2   1   0   0   1 107   0   0   0   0   1   1\n",
      "    2   0   0   0   0   1   0   0]\n",
      " [  1   0   0   0   0   0   1   0   0   0   0   0 145   1   1   0   0   0\n",
      "    0   0   0   0   3   0   0   0]\n",
      " [  0   3   0   2   0   1   0   2   0   0   0   0   5 104   3   0   0   3\n",
      "    0   0   1   1   1   0   0   0]\n",
      " [  1   0   1   4   0   0   3   0   0   0   0   0   1   5 107   2   2   2\n",
      "    0   0   0   0   4   0   0   0]\n",
      " [  0   1   0   0   2  10   1   0   0   0   0   1   0   0   0 134   1   2\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  2   1   0   2   0   0   0   0   0   0   0   1   0   0   6   2 134   0\n",
      "    0   0   0   0   0   0   1   9]\n",
      " [  0   5   0   3   0   0   0   1   0   1   2   1   0   1   0   0   0 145\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   0  10   3   2   0   1   0   0   1   0   0   0   0   1   0\n",
      "  136   3   0   0   0   1   1   3]\n",
      " [  0   0   0   1   0   3   0   1   0   0   0   0   0   1   0   0   0   0\n",
      "    2 107   0   0   0   0   7   0]\n",
      " [  2   0   3   1   0   0   0   0   0   0   0   0   3   1   0   0   3   0\n",
      "    0   0 146   0   1   0   0   0]\n",
      " [  0   4   0   0   0   2   0   0   0   0   0   0   0   0   1   2   0   2\n",
      "    0   1   0 126   4   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   2   0   0   0   1\n",
      "    0   0   1   0 141   0   0   0]\n",
      " [  0   0   0   2   7   0   2   1   2   0   6   4   0   0   1   0   0   0\n",
      "    0   0   0   0   0 132   0   0]\n",
      " [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1   3   0\n",
      "    0   2   0   2   1   1 130   0]\n",
      " [  0   0   0   0   4   0   0   0   0   3   0   0   0   0   0   0   1   1\n",
      "    7   0   0   0   0   0   0 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       145\n",
      "           1       0.82      0.84      0.83       162\n",
      "           2       0.89      0.90      0.89       137\n",
      "           3       0.81      0.92      0.86       143\n",
      "           4       0.80      0.92      0.85       140\n",
      "           5       0.84      0.84      0.84       156\n",
      "           6       0.86      0.81      0.84       156\n",
      "           7       0.90      0.72      0.80       145\n",
      "           8       0.90      0.80      0.85        86\n",
      "           9       0.90      0.87      0.88       154\n",
      "          10       0.86      0.88      0.87       142\n",
      "          11       0.87      0.90      0.88       119\n",
      "          12       0.90      0.95      0.93       152\n",
      "          13       0.87      0.83      0.85       126\n",
      "          14       0.86      0.81      0.83       132\n",
      "          15       0.86      0.88      0.87       152\n",
      "          16       0.89      0.85      0.87       158\n",
      "          17       0.80      0.91      0.85       159\n",
      "          18       0.79      0.82      0.80       165\n",
      "          19       0.91      0.88      0.90       122\n",
      "          20       0.92      0.91      0.92       160\n",
      "          21       0.93      0.89      0.91       142\n",
      "          22       0.90      0.95      0.93       148\n",
      "          23       0.96      0.84      0.90       157\n",
      "          24       0.92      0.92      0.92       142\n",
      "          25       0.87      0.88      0.88       134\n",
      "\n",
      "    accuracy                           0.87      3734\n",
      "   macro avg       0.88      0.87      0.87      3734\n",
      "weighted avg       0.88      0.87      0.87      3734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "yhat_test = final_model.predict(X_test)\n",
    "y_pred_classes1 = yhat_test.argmax(axis=-1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred_classes1 ))\n",
    "print(classification_report(y_test, y_pred_classes1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03740c8-93e8-4a18-9d7c-42e3faaa65e5",
   "metadata": {},
   "source": [
    "# Make predictions on the test set\n",
    "Training Accuracy: 91%\n",
    "\n",
    "Testing Accuracy: 89%\n",
    "\n",
    "Default Model\n",
    "\n",
    "Training Accuracy: 81.24%\n",
    "\n",
    "Testing Accuracy: 80%\n",
    "\n",
    "Overall Improvement: The tuned model outperforms the default model in both training and testing accuracy. The tuned model has higher precision, recall, and F1-scores across most classes.\n",
    "\n",
    "Consistency: The performance improvements are consistent across various metrics, indicating a well-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a0f6a-1d51-4488-8cd3-a4fed964d348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb6f28-ca68-4dd4-a280-c45b7b207494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
